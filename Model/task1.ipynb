{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYyiYxS6ZVfDtL3klK2u7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heng1222/Ohsumed_classification/blob/main/Model/task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69Twehzt4dnH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# =================================================================\n",
        "# [DATA CHANGE: 讀取 GitHub 網址資料]\n",
        "# =================================================================\n",
        "url = \"https://media.githubusercontent.com/media/Heng1222/Ohsumed_classification/refs/heads/main/classification_data/ohsumed_dataset.csv\"\n",
        "\n",
        "def fetch_and_parse_data(url):\n",
        "    print(\"正在從 GitHub 下載並解析資料...\")\n",
        "    response = requests.get(url)\n",
        "    response.encoding = 'utf-8'\n",
        "    content = response.text\n",
        "\n",
        "    # 解析格式：(標題).,\"(多行摘要)\",(標籤)\n",
        "    pattern = r'(.*?)\\.,\"([\\s\\S]*?)\",(C\\d+)'\n",
        "    matches = re.findall(pattern, content)\n",
        "\n",
        "    data_list = []\n",
        "    for m in matches:\n",
        "        data_list.append({\n",
        "            'title': m[0].strip(),\n",
        "            'abstract': m[1].replace('\\n', ' ').strip(),\n",
        "            'label': m[2].strip()\n",
        "        })\n",
        "    return pd.DataFrame(data_list)\n",
        "\n",
        "df_all = fetch_and_parse_data(url)\n",
        "\n",
        "# =================================================================\n",
        "# [實驗設定：設定要測試的特徵]\n",
        "# [DATA CHANGE: 若要換成其他欄位（如摘要），請修改 text_col]\n",
        "# =================================================================\n",
        "text_col = 'title'  # 目前設定僅使用標題進行 Baseline 測試\n",
        "label_col = 'label'\n",
        "\n",
        "print(f\"資料讀取完成，共 {len(df_all)} 筆。\")\n",
        "\n",
        "# 1. 標籤處理\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(df_all[label_col])\n",
        "\n",
        "# 2. 分層抽樣切分 (依照論文與資料分佈建議 80/20 切分)\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
        "    df_all[text_col],\n",
        "    y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded  # 必須分層抽樣以處理不平衡數據\n",
        ")\n",
        "\n",
        "# 3. 載入原始模型 (不微調)\n",
        "model_name = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 4. 定義特徵提取函數 (Baseline 核心：Linear Probing)\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(texts), batch_size), desc=\"提取 Embedding\"):\n",
        "            batch = texts.iloc[i : i + batch_size].tolist()\n",
        "            inputs = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
        "            outputs = model(**inputs)\n",
        "            # 提取 <s> 標記 (RoBERTa 的 CLS) 作為代表向量 [cite: 25]\n",
        "            emb = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            all_embeddings.append(emb)\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "print(\"提取訓練集 Embedding...\")\n",
        "X_train = get_embeddings(X_train_text)\n",
        "print(\"提取測試集 Embedding...\")\n",
        "X_test = get_embeddings(X_test_text)\n",
        "\n",
        "# 5. 訓練邏輯斯迴歸 (完全遵循論文對照組設計)\n",
        "print(\"訓練 Logistic Regression 分類器...\")\n",
        "clf = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 6. 產出評估報告\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"\\n=== 學長 Baseline RoBERTa 重現報告 (Ohsumed 資料集) ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Macro F1: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
        "print(\"\\n各類別詳細指標：\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1DHlaOQ4e-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}