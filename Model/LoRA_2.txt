
 ===============================================================================================
Layer (type:depth-idx)                                                 Param #
===============================================================================================
PeftModel                                                              --
├─LoraModel: 1-1                                                       --
│    └─RobertaModel: 2-1                                               --
│    │    └─RobertaEmbeddings: 3-1                                     (39,000,576)
│    │    └─RobertaEncoder: 3-2                                        (86,971,392)
│    │    └─RobertaPooler: 3-3                                         (590,592)
===============================================================================================
Total params: 126,562,560
Trainable params: 0
Non-trainable params: 126,562,560
===============================================================================================
classifer NN Head：

 =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Sequential                               --
├─Linear: 1-1                            17,687
=================================================================
Total params: 17,687
Trainable params: 17,687
Non-trainable params: 0
=================================================================
Epoch 1: 100%|██████████| 249/249 [04:16<00:00,  1.03s/it]
Epoch 1 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 1 Training Loss: 3.0004 Validation Loss: 2.7824
Epoch 2: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 2 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 2 Training Loss: 2.7630 Validation Loss: 2.5967
Epoch 3: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 3 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 3 Training Loss: 2.6481 Validation Loss: 2.5002
Epoch 4: 100%|██████████| 249/249 [04:21<00:00,  1.05s/it]
Epoch 4 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 4 Training Loss: 2.5745 Validation Loss: 2.4395
Epoch 5: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 5 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 5 Training Loss: 2.5057 Validation Loss: 2.3927
Epoch 6: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 6 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 6 Training Loss: 2.4852 Validation Loss: 2.3590
Epoch 7: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 7 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 7 Training Loss: 2.4613 Validation Loss: 2.3379
Epoch 8: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 8 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 8 Training Loss: 2.4247 Validation Loss: 2.3246
Epoch 9: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 9 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 9 Training Loss: 2.4113 Validation Loss: 2.3041
Epoch 10: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 10 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 10 Training Loss: 2.3950 Validation Loss: 2.2962
Epoch 11: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 11 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 11 Training Loss: 2.3648 Validation Loss: 2.2945
Epoch 12: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 12 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 12 Training Loss: 2.3666 Validation Loss: 2.2860
Epoch 13: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 13 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 13 Training Loss: 2.3591 Validation Loss: 2.2743
Epoch 14: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 14 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 14 Training Loss: 2.3555 Validation Loss: 2.2653
Epoch 15: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 15 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 15 Training Loss: 2.3416 Validation Loss: 2.2543
Epoch 16: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 16 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 16 Training Loss: 2.3219 Validation Loss: 2.2513
Epoch 17: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 17 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 17 Training Loss: 2.3337 Validation Loss: 2.2502
Epoch 18: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 18 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 18 Training Loss: 2.3366 Validation Loss: 2.2469
Epoch 19: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 19 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 19 Training Loss: 2.3075 Validation Loss: 2.2410
Epoch 20: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 20 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.11it/s]
Epoch 20 Training Loss: 2.3133 Validation Loss: 2.2356
Epoch 21: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 21 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 21 Training Loss: 2.3195 Validation Loss: 2.2356
Epoch 22: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 22 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 22 Training Loss: 2.3188 Validation Loss: 2.2340
Epoch 23: 100%|██████████| 249/249 [04:21<00:00,  1.05s/it]
Epoch 23 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 23 Training Loss: 2.3032 Validation Loss: 2.2288
Epoch 24: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 24 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.11it/s]
Epoch 24 Training Loss: 2.2944 Validation Loss: 2.2237
Epoch 25: 100%|██████████| 249/249 [04:21<00:00,  1.05s/it]
Epoch 25 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 25 Training Loss: 2.2849 Validation Loss: 2.2205
Epoch 26: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 26 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 26 Training Loss: 2.3162 Validation Loss: 2.2322
Epoch 27: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 27 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 27 Training Loss: 2.2845 Validation Loss: 2.2347
Epoch 28: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 28 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 28 Training Loss: 2.2844 Validation Loss: 2.2192
Epoch 29: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 29 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 29 Training Loss: 2.2668 Validation Loss: 2.2248
Epoch 30: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 30 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 30 Training Loss: 2.2788 Validation Loss: 2.2230
Epoch 31: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 31 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 31 Training Loss: 2.2830 Validation Loss: 2.2270
Epoch 32: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 32 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 32 Training Loss: 2.2799 Validation Loss: 2.2214
Epoch 33: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 33 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 33 Training Loss: 2.2777 Validation Loss: 2.2192
Epoch 34: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 34 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 34 Training Loss: 2.2669 Validation Loss: 2.2202
Epoch 35: 100%|██████████| 249/249 [04:23<00:00,  1.06s/it]
Epoch 35 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 35 Training Loss: 2.2745 Validation Loss: 2.2251
Epoch 36: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 36 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 36 Training Loss: 2.2688 Validation Loss: 2.2160
Epoch 37: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 37 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 37 Training Loss: 2.2734 Validation Loss: 2.2184
Epoch 38: 100%|██████████| 249/249 [04:22<00:00,  1.06s/it]
Epoch 38 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 38 Training Loss: 2.2661 Validation Loss: 2.2191
Epoch 39: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 39 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 39 Training Loss: 2.2668 Validation Loss: 2.2155
Epoch 40: 100%|██████████| 249/249 [04:22<00:00,  1.05s/it]
Epoch 40 Validation: 100%|██████████| 28/28 [00:25<00:00,  1.10it/s]
Epoch 40 Training Loss: 2.2704 Validation Loss: 2.2172

--- Final Evaluation Report ---
              precision    recall  f1-score   support

           0       0.17      0.10      0.12        42
           1       0.40      0.58      0.47        43
           2       0.47      0.53      0.50        43
           3       0.24      0.42      0.31        43
           4       0.37      0.47      0.41        43
           5       0.41      0.37      0.39        43
           6       0.50      0.40      0.44        43
           7       0.32      0.21      0.25        43
           8       0.47      0.45      0.46        42
           9       0.38      0.38      0.38        42
          10       0.53      0.40      0.45        43
          11       0.26      0.33      0.29        43
          12       0.38      0.50      0.43        42
          13       0.37      0.53      0.44        43
          14       0.28      0.26      0.27        43
          15       0.45      0.31      0.37        42
          16       0.36      0.33      0.34        43
          17       0.46      0.52      0.49        42
          18       0.31      0.26      0.28        43
          19       0.18      0.16      0.17        43
          20       0.48      0.58      0.53        43
          21       0.32      0.37      0.34        43
          22       0.00      0.00      0.00        43

    accuracy                           0.37       983
   macro avg       0.35      0.37      0.35       983
weighted avg       0.35      0.37      0.35       983
